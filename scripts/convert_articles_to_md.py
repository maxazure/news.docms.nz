#!/usr/bin/env python3
"""
å°†ç°æœ‰ HTML æ–‡ç« è½¬æ¢ä¸º Markdown æ ¼å¼
ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æï¼Œä¸ä¾èµ–å¤–éƒ¨åº“
"""

import re
import os
import subprocess

# æœåŠ¡å™¨é…ç½®
SERVER = "maxazure@192.168.31.205"
NEWS_DIR = "~/projects/news.docms.nz/news"


def extract_article_data(html_content):
    """ä»HTMLå†…å®¹ä¸­æå–æ–‡ç« æ•°æ®"""
    # æå–æ ‡é¢˜
    title_match = re.search(r'<title>(.*?)</title>', html_content, re.DOTALL)
    title = title_match.group(1).strip() if title_match else "æœªå‘½åæ–‡ç« "

    # æå–å†…å®¹åŒºåŸŸ
    content_match = re.search(r'<div class="content">(.*?)</div>', html_content, re.DOTALL)
    if not content_match:
        content_match = re.search(r'<article>(.*?)</article>', html_content, re.DOTALL)
    if not content_match:
        # æå–bodyå†…å®¹
        body_match = re.search(r'<body[^>]*>(.*?)</body>', html_content, re.DOTALL)
        content = body_match.group(1) if body_match else html_content
    else:
        content = content_match.group(1)

    # æå–å…ƒæ•°æ®
    meta = {}
    meta_match = re.search(r'<div class="meta"[^>]*>(.*?)</div>', html_content, re.DOTALL)
    if meta_match:
        meta_text = re.sub(r'<[^>]+>', '', meta_match.group(1)).strip()
        # å°è¯•æå–æ—¥æœŸ
        date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', meta_text)
        if date_match:
            year, month, day = date_match.groups()
            meta['date'] = f"{year}-{month.zfill(2)}-{day.zfill(2)}"

        # å°è¯•æå–åˆ†ç±»
        cat_match = re.search(r'åˆ†ç±»[ï¼š:]\s*([^\s|]+)', meta_text)
        if cat_match:
            meta['category'] = cat_match.group(1)

    # è½¬æ¢ä¸ºMarkdown
    markdown = convert_html_to_markdown(content, title, meta)
    return markdown, title, meta


def convert_html_to_markdown(html_content, title, meta):
    """å°†HTMLå†…å®¹è½¬æ¢ä¸ºMarkdown"""
    lines = []

    # æ·»åŠ å…ƒæ•°æ®å¤´éƒ¨
    lines.append("---")
    lines.append(f"title: {title}")
    if 'date' in meta:
        lines.append(f"date: {meta['date']}")
    if 'category' in meta:
        lines.append(f"category: {meta['category']}")
    lines.append("---")
    lines.append("")

    # ç§»é™¤scriptå’Œstyleæ ‡ç­¾
    html_content = re.sub(r'<script[^>]*>.*?</script>', '', html_content, flags=re.DOTALL)
    html_content = re.sub(r'<style[^>]*>.*?</style>', '', html_content, flags=re.DOTALL)

    # ç§»é™¤æ³¨é‡Š
    html_content = re.sub(r'<!--.*?-->', '', html_content, flags=re.DOTALL)

    # é€ä¸ªå¤„ç†å…ƒç´ 
    pos = 0
    in_list = False
    list_type = None
    list_items = []

    # å®šä¹‰æ‰€æœ‰æ ‡ç­¾çš„æ­£åˆ™æ¨¡å¼
    patterns = [
        (r'<h2[^>]*>(.*?)</h2>', 'h2'),
        (r'<h3[^>]*>(.*?)</h3>', 'h3'),
        (r'<h4[^>]*>(.*?)</h4>', 'h4'),
        (r'<h5[^>]*>(.*?)</h5>', 'h5'),
        (r'<p[^>]*>(.*?)</p>', 'p'),
        (r'<ul[^>]*>', 'ul_start'),
        (r'</ul>', 'ul_end'),
        (r'<ol[^>]*>', 'ol_start'),
        (r'</ol>', 'ol_end'),
        (r'<li[^>]*>(.*?)</li>', 'li'),
        (r'<blockquote[^>]*>(.*?)</blockquote>', 'blockquote'),
        (r'<pre[^>]*><code[^>]*>(.*?)</code></pre>', 'pre_code'),
        (r'<pre[^>]*>(.*?)</pre>', 'pre'),
        (r'<hr\s*/?>', 'hr'),
    ]

    while pos < len(html_content):
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ ‡ç­¾
        match = None
        min_pos = len(html_content)

        for pattern, tag_type in patterns:
            m = re.search(pattern, html_content[pos:], re.DOTALL)
            if m and m.start() < min_pos:
                min_pos = m.start()
                match = (m, tag_type)

        if match:
            m, tag_type = match
            # å¤„ç†æ ‡ç­¾å‰çš„æ–‡æœ¬
            before_text = html_content[pos:pos + m.start()].strip()
            if before_text and not in_list:
                # çº¯æ–‡æœ¬æ®µè½
                cleaned = clean_text(before_text)
                if cleaned:
                    lines.append("")
                    lines.append(cleaned)
                    lines.append("")

            # å¤„ç†æ ‡ç­¾
            if tag_type == 'h2':
                text = clean_text(m.group(1))
                if text:
                    lines.append("")
                    lines.append(f"## {text}")
                    lines.append("")
            elif tag_type == 'h3':
                text = clean_text(m.group(1))
                if text:
                    lines.append("")
                    lines.append(f"### {text}")
                    lines.append("")
            elif tag_type == 'h4':
                text = clean_text(m.group(1))
                if text:
                    lines.append("")
                    lines.append(f"#### {text}")
                    lines.append("")
            elif tag_type == 'p':
                text = clean_text(m.group(1))
                if text:
                    lines.append("")
                    lines.append(text)
                    lines.append("")
            elif tag_type == 'ul_start':
                in_list = True
                list_type = 'ul'
            elif tag_type == 'ol_start':
                in_list = True
                list_type = 'ol'
            elif tag_type in ['ul_end', 'ol_end']:
                # è¾“å‡ºåˆ—è¡¨
                if list_items:
                    for idx, item in enumerate(list_items, 1):
                        prefix = f"{idx}." if list_type == 'ol' else "-"
                        lines.append(prefix + " " + item)
                    if list_items:
                        lines.append("")
                in_list = False
                list_type = None
                list_items = []
            elif tag_type == 'li':
                text = clean_text(m.group(1))
                if text:
                    list_items.append(text)
            elif tag_type == 'blockquote':
                text = clean_text(m.group(1))
                if text:
                    lines.append("")
                    lines.append(f"> {text}")
                    lines.append("")
            elif tag_type == 'pre_code':
                code = m.group(1).strip()
                lines.append("")
                lines.append("```")
                lines.append(code)
                lines.append("```")
                lines.append("")
            elif tag_type == 'pre':
                code = m.group(1).strip()
                code = re.sub(r'<code[^>]*>', '', code)
                code = re.sub(r'</code>', '', code)
                lines.append("")
                lines.append("```")
                lines.append(code.strip())
                lines.append("```")
                lines.append("")
            elif tag_type == 'hr':
                lines.append("")
                lines.append("---")
                lines.append("")

            pos += m.end()
        else:
            # æ²¡æœ‰æ›´å¤šæ ‡ç­¾äº†
            remaining = html_content[pos:].strip()
            if remaining:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼
                table_match = re.search(r'<table[^>]*>(.*?)</table>', remaining, re.DOTALL)
                if table_match:
                    table_md = convert_table(table_match.group(1))
                    lines.append("")
                    lines.extend(table_md)
                    lines.append("")
                    pos += table_match.end()
                else:
                    # å¤„ç†ç‰¹æ®Šæ¡†
                    highlight_match = re.search(r'<div class="highlight-box"[^>]*>(.*?)</div>', remaining, re.DOTALL)
                    if highlight_match:
                        text = clean_text(highlight_match.group(1))
                        if text:
                            lines.append("")
                            lines.append(f"> **{text}**")
                            lines.append("")
                        pos += highlight_match.end()
                        continue

                    info_match = re.search(r'<div class="info-box"[^>]*>(.*?)</div>', remaining, re.DOTALL)
                    if info_match:
                        text = clean_text(info_match.group(1))
                        if text:
                            lines.append("")
                            lines.append(f"> ğŸ’¡ {text}")
                            lines.append("")
                        pos += info_match.end()
                        continue

                    warning_match = re.search(r'<div class="warning-box"[^>]*>(.*?)</div>', remaining, re.DOTALL)
                    if warning_match:
                        text = clean_text(warning_match.group(1))
                        if text:
                            lines.append("")
                            lines.append(f"> âš ï¸ {text}")
                            lines.append("")
                        pos += warning_match.end()
                        continue

                    # å…¶ä»–æ–‡æœ¬
                    cleaned = clean_text(remaining)
                    if cleaned:
                        lines.append("")
                        lines.append(cleaned)
                        lines.append("")
                    break
            else:
                break

    # åå¤„ç†ï¼šæ¸…ç†ç©ºè¡Œ
    result = '\n'.join(lines)
    result = re.sub(r'\n{4,}', '\n\n\n', result)
    result = result.strip()

    return result


def convert_table(table_html):
    """è½¬æ¢è¡¨æ ¼ä¸ºMarkdown"""
    lines = []

    # æå–è¡¨å¤´
    thead_match = re.search(r'<thead[^>]*>(.*?)</thead>', table_html, re.DOTALL)
    tbody_match = re.search(r'<tbody[^>]*>(.*?)</tbody>', table_html, re.DOTALL)
    tbody = tbody_match.group(1) if tbody_match else table_html

    # å¤„ç†æ‰€æœ‰è¡Œ
    rows = re.findall(r'<tr[^>]*>(.*?)</tr>', table_html, re.DOTALL)

    for idx, row in enumerate(rows):
        cells = re.findall(r'<t[dh][^>]*>(.*?)</t[dh]>', row, re.DOTALL)
        if cells:
            cleaned_cells = [clean_text(c).strip() for c in cells]
            lines.append('| ' + ' | '.join(cleaned_cells) + ' |')
            if idx == 0:
                # è¡¨å¤´åˆ†éš”çº¿
                lines.append('| ' + ' | '.join(['---'] * len(cleaned_cells)) + ' |')

    return lines


def clean_text(text):
    """æ¸…ç†HTMLæ ‡ç­¾å’Œå®ä½“"""
    if not text:
        return ""

    # å¤„ç†åŠ ç²—
    text = re.sub(r'<strong[^>]*>(.*?)</strong>', r'**\1**', text, flags=re.DOTALL)
    text = re.sub(r'<b[^>]*>(.*?)</b>', r'**\1**', text, flags=re.DOTALL)

    # å¤„ç†æ–œä½“
    text = re.sub(r'<em[^>]*>(.*?)</em>', r'*\1*', text, flags=re.DOTALL)
    text = re.sub(r'<i[^>]*>(.*?)</i>', r'*\1*', text, flags=re.DOTALL)

    # å¤„ç†ä»£ç 
    text = re.sub(r'<code[^>]*>(.*?)</code>', r'`\1`', text, flags=re.DOTALL)

    # å¤„ç†é“¾æ¥
    text = re.sub(r'<a[^>]*href="([^"]*)"[^>]*>(.*?)</a>', r'[\2](\1)', text, flags=re.DOTALL)

    # å¤„ç†æ¢è¡Œ
    text = text.replace('<br/>', '\n').replace('<br>', '\n')

    # å»é™¤å…¶ä»–æ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)

    # è§£ç HTMLå®ä½“
    text = text.replace('&nbsp;', ' ')
    text = text.replace('&lt;', '<')
    text = text.replace('&gt;', '>')
    text = text.replace('&amp;', '&')
    text = text.replace('&quot;', '"')
    text = text.replace('&apos;', "'")

    # æ¸…ç†å¤šä½™ç©ºç™½
    text = re.sub(r'\s{2,}', ' ', text)
    text = text.strip()

    return text


def get_output_filename(input_filename, index=0):
    """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼Œé¿å…å†²çª"""
    base_match = re.match(r'(\d{8})', input_filename)
    if base_match:
        base = base_match.group(1)
        # å¦‚æœåŸæ–‡ä»¶ååŒ…å«åºå·æˆ–æ—¶é—´åç¼€ï¼Œä¿ç•™å®ƒ
        suffix_match = re.match(r'\d{8}-(\d{2})', input_filename)
        time_match = re.match(r'\d{8}(\d{4})', input_filename)
        if suffix_match:
            return f"{base}-{suffix_match.group(1)}.md"
        elif time_match:
            return f"{base}{time_match.group(1)}.md"
        elif index > 0:
            return f"{base}-{str(index+1).zfill(2)}.md"
        else:
            return f"{base}.md"
    return input_filename.replace('.html', '.md')


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“° å¼€å§‹è½¬æ¢æ–‡ç« ...")

    # è·å–è¿œç¨‹æ–‡ä»¶åˆ—è¡¨
    result = subprocess.run(
        f"ssh {SERVER} 'ls {NEWS_DIR}/*.html 2>/dev/null'",
        shell=True,
        capture_output=True,
        text=True
    )

    if result.returncode != 0:
        print("âŒ æ— æ³•è·å–æ–‡ç« åˆ—è¡¨")
        return

    html_files = [f.strip() for f in result.stdout.strip().split('\n') if f.strip() and f.endswith('.html')]

    if not html_files:
        print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°HTMLæ–‡ç« ")
        return

    print(f"ğŸ“„ æ‰¾åˆ° {len(html_files)} ç¯‡æ–‡ç« ")

    # æŒ‰æ—¥æœŸåˆ†ç»„
    date_groups = {}
    for html_path in html_files:
        filename = os.path.basename(html_path)
        date_match = re.match(r'(\d{8})', filename)
        if date_match:
            date = date_match.group(1)
            if date not in date_groups:
                date_groups[date] = []
            date_groups[date].append(filename)
        else:
            # æ— æ—¥æœŸæ–‡ä»¶
            if '_other' not in date_groups:
                date_groups['_other'] = []
            date_groups['_other'].append(filename)

    # è½¬æ¢æ¯ç¯‡æ–‡ç« 
    converted = []
    for date, files in sorted(date_groups.items()):
        for idx, filename in enumerate(sorted(files)):
            print(f"\nğŸ”„ å¤„ç†: {filename}")

            # ä¸‹è½½HTMLå†…å®¹
            result = subprocess.run(
                f"ssh {SERVER} 'cat {NEWS_DIR}/{filename}'",
                shell=True,
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                print(f"  âŒ ä¸‹è½½å¤±è´¥")
                continue

            html_content = result.stdout

            # è½¬æ¢
            try:
                md_content, title, meta = extract_article_data(html_content)
                if not md_content:
                    print(f"  âŒ è§£æå¤±è´¥")
                    continue

                # å¦‚æœåŒä¸€å¤©æœ‰å¤šç¯‡æ–‡ç« ï¼Œä½¿ç”¨åŸæ–‡ä»¶åä¸­çš„åç¼€æˆ–æ·»åŠ åºå·
                output_filename = get_output_filename(filename, idx if len(files) > 1 else -1)

                # å†™å…¥åˆ°æœåŠ¡å™¨ï¼ˆä½¿ç”¨catå‘½ä»¤ï¼‰
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                local_tmp = f"/tmp/{output_filename}"
                with open(local_tmp, 'w', encoding='utf-8') as f:
                    f.write(md_content)

                # ä¸Šä¼ åˆ°æœåŠ¡å™¨
                subprocess.run(
                    f"scp {local_tmp} {SERVER}:{NEWS_DIR}/{output_filename}",
                    shell=True,
                    capture_output=True
                )
                os.remove(local_tmp)

                print(f"  âœ… å·²è½¬æ¢: {output_filename}")
                if title:
                    print(f"     æ ‡é¢˜: {title}")
                converted.append(output_filename)

            except Exception as e:
                print(f"  âŒ è½¬æ¢å¤±è´¥: {e}")

    print(f"\n\nğŸ“Š è½¬æ¢å®Œæˆ!")
    print(f"âœ… æˆåŠŸ: {len(converted)} ç¯‡")
    print(f"\nè½¬æ¢çš„æ–‡ä»¶:")
    for f in converted:
        print(f"  - {f}")

    # å¤‡ä»½åŸHTMLæ–‡ä»¶
    print(f"\nğŸ’¾ å¤‡ä»½åŸHTMLæ–‡ä»¶åˆ° _html ç›®å½•...")
    subprocess.run(
        f"ssh {SERVER} 'mkdir -p {NEWS_DIR}/_html && mv {NEWS_DIR}/*.html {NEWS_DIR}/_html/ 2>/dev/null || true'",
        shell=True
    )
    print("âœ… å¤‡ä»½å®Œæˆ")


if __name__ == "__main__":
    main()
