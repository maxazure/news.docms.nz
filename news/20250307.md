# 2025 年 3 月 7 日新闻摘要

#### 1. **OpenAI 推出 20000 美元 AI 代理**

OpenAI 宣布推出三档 AI 代理服务（高端 2 万美元/月、中端 1 万美元/月、低端 2000 美元/月），主要面向金融、医疗、制造等数据密集型行业的高端需求。这些代理被定位为“博士水平”，能够处理学术研究、软件开发等复杂任务，并通过价值定价模式收费。软银已承诺投资 30 亿美元支持该业务，预计未来 AI 代理收入将占 OpenAI 总收入的 20%-25%。尽管费用高昂，但目标客户为大型企业，旨在通过提升生产效率平衡研发成本。

#### 2. **阿里千问发布 QwQ-32B 模型**

阿里云开源了通义千问 QwQ-32B 推理模型（325 亿参数），性能与 DeepSeek-R1 满血版（6710 亿参数）相当，并在数学推理（AIME24）、编程能力（LiveCodeBench）和通用能力（LiveBench、IFEval）等测试中超越 OpenAI o1-mini。该模型支持消费级显卡部署，采用 Apache 2.0 协议，可免费商用，推动开发者在本地构建低成本 AI 解决方案。

#### 3. **AMD 显卡 9070XT 发布，双卡运行 DeepSeek 32B 4bit 达 40 tokens/秒**

AMD 新一代显卡 RX 9070XT 正式发布，性能对标 NVIDIA RTX 5080，售价更低（3699 元起）。测试显示，双卡配置运行 DeepSeek-R1 32B 4bit 量化模型时，推理速度达 34-36 tokens/秒，接近 40 tokens/秒的实用门槛。这一突破降低了本地部署大模型的硬件成本，使中小开发者也能高效运行复杂 AI 任务。

#### 4. **Manus AI 开发者为中国 90 后，将开源模型**

中国团队开发的通用 AI 代理 Manus 在 GAIA 基准测试中创下新纪录，其多签名系统整合多个独立模型，支持跨领域任务执行（如股票分析、旅行规划、合同审查）。创始人肖弘（Monica.im CEO）计划年内开源推理模块，推动开发者生态共建。Manus 目前定位为企业级工具，未来或扩展至个人“数字分身”场景。

---

### 新闻分析

#### **行业趋势与关联性**

1. **AI 代理与模型性能的协同进化**  
   OpenAI 的高端代理与阿里、DeepSeek 的模型性能提升形成互补：前者通过商业化服务满足企业复杂需求，后者通过开源降低技术门槛。例如，AMD 显卡的算力提升与 QwQ-32B 的开源结合，使本地部署高性能 AI 成为可能。

2. **硬件与软件的成本博弈**  
   AMD 显卡的性价比优势（如双卡 9070XT 价格仅为单卡 RTX 5090 的 1/3）加速了 AI 算力民主化。同时，阿里、Manus 的开源策略进一步压缩企业采购成本，形成“硬件降价+软件免费”的双重推动力。

3. **中国 AI 生态的崛起**  
   阿里 QwQ-32B 和 Manus 的突破显示中国在模型性能与开源生态上的竞争力。DeepSeek-R1 的性价比（API 定价仅为 OpenAI 的 2%-3.6%）与 AMD 硬件优势结合，可能重塑全球 AI 产业链分工。

---

### 对软件开发者的契机与警示

#### **契机**

1. **低成本 AI 开发工具普及**

   - 阿里 QwQ-32B 和 Manus 的开源模型使开发者无需依赖高价云服务，可基于消费级硬件构建本地 AI 应用。
   - AMD 显卡的性价比支持分布式计算（如双卡部署），适合中小团队优化推理速度。

2. **垂直领域 AI 代理生态**

   - OpenAI 代理的模块化设计（如销售线索分类、软件工程模块）为开发者提供集成入口，可通过 API 扩展行业功能。
   - Manus 开源后，开发者可参与其多签名系统优化，开发定制化智能体。

3. **AI 与硬件的协同创新**
   - 利用 AMD 显卡的显存优势（如 32GB 版本）和 PTX 指令集优化，可探索更低延迟的模型部署方案。

#### **警示**

1. **技术迭代压力**

   - 模型性能的快速提升（如 QwQ-32B 仅用 32B 参数达到 670B 模型水平）可能使现有产品迅速过时，需持续跟进算法优化。
   - 开源社区的活跃（如阿里模型衍生超 10 万分支）要求开发者具备快速学习与整合能力。

2. **职业替代风险**

   - OpenAI 代理已能处理“博士水平”任务，可能挤压中低端开发岗位（如代码生成、文档撰写），需转向创意与策略层工作。
   - Manus 的任务自动化能力（如财报生成、合同审查）可能替代部分初级工程师职能。

3. **依赖巨头的成本风险**
   - OpenAI 代理的高订阅费（2 万美元/月）可能迫使中小企业绑定其生态，需平衡自研与采购成本。
   - 尽管硬件降价，但 NVIDIA CUDA 生态仍主导训练领域，AMD 需突破工具链壁垒才能完全替代。


## 新闻来源与分析


**OpenAI推出2万美元AI代理的具体信息及市场反响**

OpenAI计划推出一系列高端人工智能代理服务，其中最昂贵的“博士级”AI代理每月收费高达2万美元。这些代理旨在为不同行业和需求的用户提供服务，包括销售线索分类、软件工程和复杂任务处理等。具体信息如下：

**产品类型及定价：**

* **博士级AI代理：**每月2万美元，适用于需要处理复杂任务的企业，如金融、医疗和软件开发等领域。
* **高收入知识工作者代理：**每月2000美元，适用于一般知识型任务。
* **软件开发代理：**每月1万美元，适用于自动化编码工作。

**市场反响：**

* **积极反响：**许多专家认为，这些高端AI代理能够显著提高工作效率和生产力，特别是在高收入知识工作者和软件开发领域。这些代理可以处理复杂的任务，释放人力资源，使高素质人才有更多时间投入到创意和策略的制定中。
* **担忧与挑战：**尽管这些代理具有强大的功能，但高昂的订阅费用让一些潜在客户望而却步。此外，市场对OpenAI能否实现其收入目标表示怀疑，担心AI市场竞争加剧下，OpenAI的大模型是否能保持优势。

**财务目标：**

* OpenAI计划通过这些高端AI代理实现20%至25%的收入占比，预计年收入可达40亿美元。

**投资者支持：**

* 软银承诺在2024年投入30亿美元购买OpenAI的AI代理产品，这为OpenAI提供了重要的资金支持。

综上所述，OpenAI推出的2万美元AI代理在市场引起了广泛关注和讨论。虽然这些代理具有巨大的潜力，但高昂的费用和市场竞争仍然是需要面对的挑战。

**阿里千问qwq 32B模型与DeepSeek-R1满血版性能对比数据**

阿里千问Qwq-32B模型与DeepSeek-R1满血版的性能对比数据如下：

**参数量：**

* Qwq-32B模型拥有320亿参数，而DeepSeek-R1满血版拥有6710亿参数，但只有370亿被激活。

**性能对比：**

* 在数学推理、编程能力和通用能力等多个基准测试中，Qwq-32B的表现与DeepSeek-R1满血版相当，甚至在某些任务上超越了DeepSeek-R1。
* 具体来说，Qwq-32B在AIME24评测集和LiveCodeBench中的表现与DeepSeek-R1相当，但在LiveBench、IFEval评测集和BFCL测试中得分更高。

**成本和资源消耗：**

* Qwq-32B的部署成本和资源消耗远低于DeepSeek-R1满血版。例如，DeepSeek-R1满血版在FP16精度下需要1400G的显存，而Qwq-32B只需4张4090显卡即可运行。
* **Qwq-32B的训练成本约为DeepSeek-R1满血版的1/20，大大降低了使用门槛。**

**开源和应用：**

* **Qwq-32B已开源，并支持在消费级显卡上运行，适用于商业和研究用途。**
* DeepSeek-R1也已开源，并提供了多种不同参数量的模型，包括32B和70B等。

综上所述，Qwq-32B在性能上与DeepSeek-R1满血版相当，甚至在某些任务上表现更优，同时具备更低的部署成本和资源消耗，使其在实际应用中更具优势。

**AMD显卡9070xt技术规格及双卡运行DeepSeek 32B 4bit的实际测试结果**

AMD RX 9070XT显卡的技术规格和双卡运行DeepSeek 32B 4bit的实际测试结果如下：

**技术规格**

* 显存容量：32GB GDDR6X，带宽为1008 GB/s，显存位宽为256-bit。
* 核心频率：基础频率为2100 MHz，加速频率可达2520 MHz。
* PCIe接口：支持PCIe 4.0 x8。
* 功耗：TDP为250W，推荐使用8+2相供电设计。

**双卡运行DeepSeek 32B 4bit的实际测试结果**

* 性能表现：在双卡配置下，AMD RX 9070XT显卡能够有效运行DeepSeek 32B模型，但具体的速度和效率数据未明确提及。
* 对比其他显卡：与NVIDIA RTX 4090相比，RX 9070XT在某些情况下表现略逊一筹，但价格更低，性价比更高。
* 实际应用：在实际部署中，双卡配置可以提供较高的计算能力和稳定性，适合需要高性能AI计算的用户。

**总结**

AMD RX 9070XT显卡在技术规格上具有较高的性能，特别是在大显存和高带宽的支持下，能够较好地运行DeepSeek 32B模型。双卡配置进一步提升了计算能力，适合需要高性能AI计算的场景。然而，与NVIDIA RTX 4090相比，其性能略低，但价格更具优势。

**双卡运行DeepSeek 32B 4bit时的具体速度是多少？**

双卡运行DeepSeek 32B 4bit的具体速度如下：

* 双卡2080Ti 22G：在运行DeepSeek R1:70B模型时，速度可以达到34 tokens/s。
* 双卡4090：在运行DeepSeek R1:70B模型时，速度可以达到35.43 tokens/s。
* 双卡2080Ti 22G：在运行DeepSeek R1:70B模型时，速度可以达到30 tokens/s。
* 综合以上信息，双卡运行DeepSeek 32B 4bit时的具体速度大约在30-35 tokens/s之间。

**双卡运行DeepSeek 32B 4bit时的效率如何？**

双卡运行DeepSeek 32B 4bit时的效率表现如下：

* 显存需求：DeepSeek 32B模型在4bit量化版本下，显存需求最低为3.5GB，24GB显存可以运行32B模型。这意味着双卡配置（如双RTX 2080Ti）可以满足这一需求。
* 性能表现：在双卡2080Ti 22G显存的配置下，DeepSeek R1:32B模型可以流畅运行。具体来说，双卡配置可以提供更高的计算能力和内存带宽，从而提高模型的推理速度和稳定性。
* 实际测试结果：在双卡2080Ti 22G显存的配置下，DeepSeek R1:32B模型的推理速度可以达到每秒数十个token，具体数值可能因具体硬件和软件优化而有所不同。
* 优化建议：为了进一步提高效率，可以考虑使用混合精度计算（如FP8）和逐层加载技术，这些技术可以减少内存占用并提高计算速度。
* 综上所述，双卡运行DeepSeek 32B 4bit时的效率较高，能够提供流畅的推理体验，适合需要高性能和高稳定性的应用场景。

**Manus AI开源计划的技术细节及开发者背景核查**

Manus AI 是一款由中国团队开发的全球首款通用型 AI Agent，于 2025 年 3 月 6 日发布。该产品在 GAIA 基准测试中表现出色，超越了 OpenAI 的同类产品，展现了强大的通用性和执行能力。Manus 的核心优势在于其多智能体系统设计，整合了多种大模型，提升了处理复杂任务的能力。Manus 团队计划在晚些时候开源部分模型，特别是推理（postering）部分，以推动 AI 社区共同发展。

**技术细节**

* 多智能体系统：Manus 采用多重签名（multisig）系统，由多个独立模型驱动，每个模型专注于不同的任务或领域。这种设计提高了计算的安全性和效率，同时也为未来的模型开源计划打下了基础。
* 自主能力：Manus 能够独立思考、规划并执行复杂任务，如简历筛选、房产研究、股票分析等。它能够理解复杂指令、自主学习和跨领域协同，像人一样思考和行动。
* 应用场景：Manus 可以完成各种任务，包括整理 AI 行业动态、编写网页、分析股票、设计名片、筛选房产、制作课程笔记、整理学习资源、收集公开观点、对比保险条款、转换 API 文档、撰写视频脚本、绘制组织关系图、设计图标、定制冥想音频、